<h1 style="text-align: center;">&nbsp;</h1>
<h1 style="text-align: center;">THE ZERO OHM RESISTOR</h1>
<div>
<p>What&rsquo;s your favorite value of resistor? 1K? 10K? They&rsquo;re all fine, but when you need nearly no resistance at all, nothing beats the good old zero-ohm resistor.</p>
<p>Wait a minute! Resistors are supposed to resist current. What the heck does a zero-ohm resistor do? Well, the short story (tee-hee!) is that it&rsquo;s like a jumper for single-sided surface-mount boards. In the bad old days, companies used to save money by running single-sided boards, and you could buy wire jumpers to help make the layout that much easier.</p>
<p>Fast forward to the modern era, where there&rsquo;s not a through-hole component to be seen. What&rsquo;s the resistance (ideally) of a wire? Zero ohms. And thus the zero-ohm resistor was born. We have a whole spool of them in our closet in 1206, the largest SMD size that we use, in order to be able to sneak two or three tracks underneath, even on a home-etched board. They&rsquo;re great.</p>
<p>Anyway, what set us off rhapsodizing about the lowest value resistor was&nbsp;this article on the peculiarities of the zero ohm resistor. Of course, nothing has zero resistance, and the article walks you through some of their real-world properties. Enjoy!</p>
</div>
<h1 style="text-align: center;">&nbsp;<img style="font-family: Lora, 'Times New Roman', serif; font-size: 20px;" src="https://hackadaycom.files.wordpress.com/2016/11/dscf9062_featured.png?w=800" /></h1>
<h2>Using these bad Larrys</h2>
<p>Speech synthesis is nothing new, but it has gotten better lately. It is about to get even better thanks to&nbsp;DeepMind&rsquo;s WaveNet project. The Alphabet (or is it Google?) project uses neural networks to analyze audio data and it learns to speak by example. Unlike other text-to-speech systems, WaveNet creates sound one sample at a time and affords surprisingly human-sounding results.</p>
<p>Before you rush to comment &ldquo;Not a hack!&rdquo; you should know we are seeing projects pop up on GitHub that use the technology. For example,&nbsp;there is a&nbsp;concrete implementation&nbsp;by [ibab]. [Tomlepaine] has&nbsp;<a href="https://github.com/tomlepaine/fast-wavenet" target="_blank" rel="noopener noreferrer">an optimized&nbsp;version</a>. In addition to learning English, they successfully trained it for Mandarin and even to generate music. If you don&rsquo;t want to build a system out yourself, the original paper has audio files (about midway down) comparing traditional parametric and concatenative voices with the WaveNet voices.</p>
<p>Another interesting project is the reverse path &mdash; teaching&nbsp;<a href="https://github.com/buriburisuri/speech-to-text-wavenet" target="_blank" rel="noopener noreferrer">WaveNet to convert speech to text</a>. Before you get too excited, though, you might want to note this quote from the read me file:</p>
<blockquote>
<p>&ldquo;We&rsquo;ve trained this model on a single Titan X GPU during 30 hours until 20 epochs and the model stopped at 13.4 ctc loss. If you don&rsquo;t have a Titan X GPU, reduce batch_size in the train.py file from 16 to 4.&rdquo;</p>
</blockquote>
<p>Last time we checked, you could get a Titan X for a little less than $2,000.</p>
<p>There is a multi-part lecture series on reinforced learning (the foundation for DeepMind). If you wanted to tackle a project yourself, that might be a&nbsp;good starting point (the first part appears below).</p>